{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1Nychgbr6dptgEsUkJCBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trece37/akiles1337-colab/blob/main/ACHILLES_LSTM_V3_1_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REpVyS3OnZJc",
        "outputId": "96b1b877-3234-4006-8ffb-4f2b003fe50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " ACHILLES LSTM V3.1 - TRAINING PIPELINE\n",
            "======================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "GPUs disponibles: 1\n",
            "TensorFlow version: 2.19.0\n",
            "\n",
            "✅ GPU detectada: /physical_device:GPU:0\n",
            "Entrenamiento optimizado (45-90 minutos)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ACHILLES LSTM V3.1 - TRAINING PIPELINE\n",
        "# Enciclopedia Akiles1337 - Proyecto LLM1337\n",
        "# Fecha: 26 Noviembre 2025\n",
        "# ============================================================\n",
        "\n",
        "# CELDA 1: Setup Inicial y Verificacion de GPU\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print('=' * 70)\n",
        "print(' ACHILLES LSTM V3.1 - TRAINING PIPELINE')\n",
        "print('=' * 70)\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verificar GPU\n",
        "print(f\"\\nGPUs disponibles: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "if len(tf.config.list_physical_devices('GPU')) == 0:\n",
        "    print('\\n⚠️ ADVERTENCIA: No se detecto GPU')\n",
        "    print('Entrenamiento sera LENTO (4-6 horas)')\n",
        "else:\n",
        "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
        "    print(f\"\\n✅ GPU detectada: {gpu.name}\")\n",
        "    print('Entrenamiento optimizado (45-90 minutos)')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 2: Instalar dependencias e imports\n",
        "!pip install -q pandas-ta scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Attention, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "print('\\n✅ Imports completados correctamente')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKpwWhSonzDk",
        "outputId": "eb4e481c-85ca-4de8-f7e4-386512b39a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.3/240.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "✅ Imports completados correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 3: Configuracion e Hiperparametros\n",
        "# ============================================================\n",
        "# RUTAS - AJUSTA SEGUN TU GOOGLE DRIVE\n",
        "# ============================================================\n",
        "DATAPATH = '/content/drive/MyDrive/AchillesTraining/data/XAUUSD.csv'\n",
        "OUTPUTDIR = '/content/drive/MyDrive/AchillesTraining/output/v3.1'\n",
        "\n",
        "# Hiperparametros segun Enciclopedia Akiles1337\n",
        "WINDOW_SIZE = 60          # Ventana temporal: 60 minutos\n",
        "TRAIN_TEST_SPLIT = 0.8    # 80% train, 20% test\n",
        "EPOCHS = 100              # Maximo de epocas\n",
        "BATCH_SIZE = 64           # Tamano del batch\n",
        "LEARNING_RATE = 0.001     # Learning rate inicial\n",
        "MODEL_VERSION = 'v3.1.0'  # Versionado semantico\n",
        "\n",
        "# Crear carpetas de salida\n",
        "os.makedirs(OUTPUTDIR, exist_ok=True)\n",
        "\n",
        "print('=' * 70)\n",
        "print(' CONFIGURACION')\n",
        "print('=' * 70)\n",
        "print(f' Ruta datos: {DATAPATH}')\n",
        "print(f' Ruta salida: {OUTPUTDIR}')\n",
        "print(f'\\n Hiperparametros:')\n",
        "print(f'   Window size: {WINDOW_SIZE} minutos')\n",
        "print(f'   Train/Test: {TRAIN_TEST_SPLIT*100:.0f}% / {(1-TRAIN_TEST_SPLIT)*100:.0f}%')\n",
        "print(f'   Epocas max: {EPOCHS}')\n",
        "print(f'   Batch size: {BATCH_SIZE}')\n",
        "print(f'   Learning rate: {LEARNING_RATE}')\n",
        "print(f'   Version modelo: {MODEL_VERSION}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09InE9Lcn4Rc",
        "outputId": "cab46577-6ee5-45ef-d278-f3e007290718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CONFIGURACION\n",
            "======================================================================\n",
            " Ruta datos: /content/drive/MyDrive/AchillesTraining/data/XAUUSD.csv\n",
            " Ruta salida: /content/drive/MyDrive/AchillesTraining/output/v3.1\n",
            "\n",
            " Hiperparametros:\n",
            "   Window size: 60 minutos\n",
            "   Train/Test: 80% / 20%\n",
            "   Epocas max: 100\n",
            "   Batch size: 64\n",
            "   Learning rate: 0.001\n",
            "   Version modelo: v3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 4: Feature Engineering - 9 Indicadores Técnicos\n",
        "# ============================================================\n",
        "def add_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Añade indicadores técnicos como features adicionales.\n",
        "    Basado en Enciclopedia Akiles1337 - Capítulo 4\n",
        "\n",
        "    Features:\n",
        "        1. close      - Precio de cierre (base)\n",
        "        2. rsi        - Relative Strength Index (sobrecompra/sobreventa)\n",
        "        3. ema20      - EMA corto plazo\n",
        "        4. ema50      - EMA medio plazo\n",
        "        5. atr        - Average True Range (volatilidad)\n",
        "        6. macd       - MACD\n",
        "        7. macd_signal- Señal MACD\n",
        "        8. bb_upper   - Bollinger Band Superior\n",
        "        9. bb_lower   - Bollinger Band Inferior\n",
        "    \"\"\"\n",
        "    print('Calculando indicadores técnicos...')\n",
        "\n",
        "    # RSI - 14 periodos\n",
        "    df['rsi'] = ta.rsi(df['close'], length=14)\n",
        "    print('  RSI calculado (14 periodos)')\n",
        "\n",
        "    # EMAs - 20 y 50 periodos\n",
        "    df['ema20'] = ta.ema(df['close'], length=20)\n",
        "    df['ema50'] = ta.ema(df['close'], length=50)\n",
        "    print('  EMA calculadas (20, 50 periodos)')\n",
        "\n",
        "    # ATR - volatilidad\n",
        "    df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=14)\n",
        "    print('  ATR calculado (volatilidad)')\n",
        "\n",
        "    # MACD + señal\n",
        "    macd = ta.macd(df['close'])\n",
        "    df['macd'] = macd['MACD_12_26_9']\n",
        "    df['macd_signal'] = macd['MACDs_12_26_9']\n",
        "    print('  MACD + señal calculado')\n",
        "\n",
        "    # Bandas de Bollinger (robusto ante cambios de versión)\n",
        "    bbands = ta.bbands(df['close'], length=20)\n",
        "    print(\"  Columnas BBANDS generadas:\", bbands.columns.tolist())    # Para verificar los nombres\n",
        "\n",
        "    # Detecta los nombres automáticamente\n",
        "    bb_upper_col = next(c for c in bbands.columns if \"BBU\" in c)\n",
        "    bb_lower_col = next(c for c in bbands.columns if \"BBL\" in c)\n",
        "    df['bb_upper'] = bbands[bb_upper_col]\n",
        "    df['bb_lower'] = bbands[bb_lower_col]\n",
        "    print('  Bollinger Bands calculadas')\n",
        "\n",
        "    # Eliminar NaN generados por indicadores\n",
        "    initial_rows = len(df)\n",
        "    df = df.dropna()\n",
        "    dropped_rows = initial_rows - len(df)\n",
        "    print(f'\\n  Filas eliminadas (NaN): {dropped_rows}')\n",
        "    print(f'  Filas finales: {len(df)}')\n",
        "\n",
        "    print('✅ Funcion add_technical_indicators definida')\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "nkJqDI9Vn-8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 5: Cargar datos y preprocesar\n",
        "# ============================================================\n",
        "print('=' * 70)\n",
        "print(' CARGANDO DATOS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Cargar CSV\n",
        "df = pd.read_csv(DATAPATH)\n",
        "print(f'\\n Archivo cargado: {DATAPATH}')\n",
        "print(f' Filas totales: {len(df):,}')\n",
        "print(f' Columnas: {list(df.columns)}')\n",
        "\n",
        "# Mostrar primeras filas\n",
        "print(f'\\n Primeras filas:')\n",
        "print(df.head())\n",
        "\n",
        "# Aplicar feature engineering\n",
        "print(f'\\n' + '=' * 70)\n",
        "print(' FEATURE ENGINEERING')\n",
        "print('=' * 70)\n",
        "df = add_technical_indicators(df)\n",
        "\n",
        "# Seleccionar features para el modelo (9 features)\n",
        "FEATURE_COLUMNS = ['close', 'rsi', 'ema20', 'ema50', 'atr', 'macd', 'macd_signal', 'bb_upper', 'bb_lower']\n",
        "data = df[FEATURE_COLUMNS].values\n",
        "\n",
        "print(f'\\n Features seleccionadas: {FEATURE_COLUMNS}')\n",
        "print(f' Shape datos: {data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0VGwThjoJaB",
        "outputId": "8bbb99ab-97d3-4903-9711-36baf70edb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CARGANDO DATOS\n",
            "======================================================================\n",
            "\n",
            " Archivo cargado: /content/drive/MyDrive/AchillesTraining/data/XAUUSD.csv\n",
            " Filas totales: 50,000\n",
            " Columnas: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume']\n",
            "\n",
            " Primeras filas:\n",
            "                  time     open     high      low    close  tick_volume  \\\n",
            "0  2025-10-07 10:19:00  3950.42  3950.71  3949.67  3950.00           85   \n",
            "1  2025-10-07 10:20:00  3950.02  3950.47  3946.59  3947.76           98   \n",
            "2  2025-10-07 10:21:00  3947.75  3948.47  3945.76  3947.45           97   \n",
            "3  2025-10-07 10:22:00  3948.03  3948.03  3944.19  3944.19           94   \n",
            "4  2025-10-07 10:23:00  3944.25  3947.78  3944.00  3947.32           91   \n",
            "\n",
            "   spread  real_volume  \n",
            "0      15            0  \n",
            "1      15            0  \n",
            "2       5            0  \n",
            "3       6            0  \n",
            "4       5            0  \n",
            "\n",
            "======================================================================\n",
            " FEATURE ENGINEERING\n",
            "======================================================================\n",
            "Calculando indicadores técnicos...\n",
            "  RSI calculado (14 periodos)\n",
            "  EMA calculadas (20, 50 periodos)\n",
            "  ATR calculado (volatilidad)\n",
            "  MACD + señal calculado\n",
            "  Columnas BBANDS generadas: ['BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0']\n",
            "  Bollinger Bands calculadas\n",
            "\n",
            "  Filas eliminadas (NaN): 49\n",
            "  Filas finales: 49951\n",
            "✅ Funcion add_technical_indicators definida\n",
            "\n",
            " Features seleccionadas: ['close', 'rsi', 'ema20', 'ema50', 'atr', 'macd', 'macd_signal', 'bb_upper', 'bb_lower']\n",
            " Shape datos: (49951, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 6: Train/Test Split y Normalizacion (SIN DATA LEAKAGE)\n",
        "# ============================================================\n",
        "# IMPORTANTE: Scaler se ajusta SOLO con datos de entrenamiento\n",
        "# Segun ANEXO 2 de Enciclopedia Akiles1337\n",
        "# ============================================================\n",
        "print('=' * 70)\n",
        "print(' TRAIN/TEST SPLIT Y NORMALIZACION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Calcular punto de division\n",
        "split_idx = int(len(data) * TRAIN_TEST_SPLIT)\n",
        "\n",
        "# Dividir datos ANTES de normalizar\n",
        "train_data = data[:split_idx]\n",
        "test_data = data[split_idx:]\n",
        "\n",
        "print(f'\\n Train samples: {len(train_data):,}')\n",
        "print(f' Test samples: {len(test_data):,}')\n",
        "\n",
        "# Crear scaler y ajustar SOLO con datos de entrenamiento (evita data leakage)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(train_data)  # Solo fit con train!\n",
        "\n",
        "# Transformar ambos conjuntos\n",
        "train_scaled = scaler.transform(train_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "print(f'\\n✅ Scaler ajustado SOLO con datos de entrenamiento')\n",
        "print(f' Rango normalizado: [0, 1]')\n",
        "print(f' Train scaled shape: {train_scaled.shape}')\n",
        "print(f' Test scaled shape: {test_scaled.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45_-0r-moP9z",
        "outputId": "40933735-8064-45a8-cda7-2f24353d43f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " TRAIN/TEST SPLIT Y NORMALIZACION\n",
            "======================================================================\n",
            "\n",
            " Train samples: 39,960\n",
            " Test samples: 9,991\n",
            "\n",
            "✅ Scaler ajustado SOLO con datos de entrenamiento\n",
            " Rango normalizado: [0, 1]\n",
            " Train scaled shape: (39960, 9)\n",
            " Test scaled shape: (9991, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 7: Crear secuencias temporales para LSTM\n",
        "# ============================================================\n",
        "def create_sequences(data, window_size):\n",
        "    \"\"\"\n",
        "    Crea secuencias temporales para entrenamiento LSTM.\n",
        "    Input: ultimos 60 minutos (window_size)\n",
        "    Output: precio del minuto siguiente (close)\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(data)):\n",
        "        X.append(data[i-window_size:i])  # Ultimos 60 minutos\n",
        "        y.append(data[i, 0])  # Precio close del siguiente minuto\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "print('=' * 70)\n",
        "print(' CREANDO SECUENCIAS TEMPORALES')\n",
        "print('=' * 70)\n",
        "\n",
        "# Crear secuencias para train y test\n",
        "X_train, y_train = create_sequences(train_scaled, WINDOW_SIZE)\n",
        "X_test, y_test = create_sequences(test_scaled, WINDOW_SIZE)\n",
        "\n",
        "print(f'\\n Secuencias creadas:')\n",
        "print(f'   X_train shape: {X_train.shape} (samples, timesteps, features)')\n",
        "print(f'   y_train shape: {y_train.shape}')\n",
        "print(f'   X_test shape: {X_test.shape}')\n",
        "print(f'   y_test shape: {y_test.shape}')\n",
        "\n",
        "print(f'\\n✅ Datos listos para entrenar Bi-LSTM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff5K05nXoWib",
        "outputId": "4852b6d9-7456-480d-d5aa-87d34be78244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CREANDO SECUENCIAS TEMPORALES\n",
            "======================================================================\n",
            "\n",
            " Secuencias creadas:\n",
            "   X_train shape: (39900, 60, 9) (samples, timesteps, features)\n",
            "   y_train shape: (39900,)\n",
            "   X_test shape: (9931, 60, 9)\n",
            "   y_test shape: (9931,)\n",
            "\n",
            "✅ Datos listos para entrenar Bi-LSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 8: Arquitectura Bi-LSTM + Self-Attention (Achilles V3.1)\n",
        "# ============================================================\n",
        "# Segun Capitulo 3 de Enciclopedia Akiles1337\n",
        "# ============================================================\n",
        "def build_achilles_model(input_shape):\n",
        "    \"\"\"\n",
        "    Arquitectura Achilles LSTM V3.1:\n",
        "    - Bidirectional LSTM (64 neuronas) con L1/L2 regularization\n",
        "    - Dropout 40%\n",
        "    - BatchNormalization\n",
        "    - Self-Attention Layer\n",
        "    - Bidirectional LSTM (32 neuronas)\n",
        "    - Dropout 30%\n",
        "    - Dense output (1 neurona - precio predicho)\n",
        "    \"\"\"\n",
        "    # Input Layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Bidirectional LSTM Layer 1 (64 neuronas x 2 direcciones)\n",
        "    lstm1 = Bidirectional(\n",
        "        LSTM(64, return_sequences=True,\n",
        "             kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))\n",
        "    )(inputs)\n",
        "    lstm1 = Dropout(0.4)(lstm1)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "\n",
        "    # Self-Attention Layer\n",
        "    attention = Attention()([lstm1, lstm1])\n",
        "\n",
        "    # Concatenate LSTM output con Attention\n",
        "    concat = Concatenate()([lstm1, attention])\n",
        "\n",
        "    # Bidirectional LSTM Layer 2 (32 neuronas x 2 direcciones)\n",
        "    lstm2 = Bidirectional(\n",
        "        LSTM(32, return_sequences=False)\n",
        "    )(concat)\n",
        "    lstm2 = Dropout(0.3)(lstm2)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(1)(lstm2)\n",
        "\n",
        "    # Compilar modelo\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print('=' * 70)\n",
        "print(' ARQUITECTURA ACHILLES LSTM V3.1')\n",
        "print('=' * 70)\n",
        "\n",
        "# Construir modelo\n",
        "model = build_achilles_model((WINDOW_SIZE, len(FEATURE_COLUMNS)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "oJXOVRqeod2F",
        "outputId": "13069e7a-86ec-4e7a-ac83-056d7b4f40f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " ARQUITECTURA ACHILLES LSTM V3.1\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m37,888\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m73,984\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,888</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,449\u001b[0m (439.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,449</span> (439.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,193\u001b[0m (438.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,193</span> (438.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 9: Entrenamiento con Callbacks\n",
        "# ============================================================\n",
        "print('=' * 70)\n",
        "print(' ENTRENAMIENTO')\n",
        "print('=' * 70)\n",
        "\n",
        "# Callbacks para optimizar entrenamiento\n",
        "callbacks = [\n",
        "    # Early Stopping - para si no mejora en 15 epocas\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Reducir LR si no mejora en 10 epocas\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Guardar mejor modelo\n",
        "    ModelCheckpoint(\n",
        "        filepath=f'{OUTPUTDIR}/best_model.keras',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f'\\n Iniciando entrenamiento...')\n",
        "print(f' Epocas max: {EPOCHS}')\n",
        "print(f' Batch size: {BATCH_SIZE}')\n",
        "print(f' Early stopping patience: 15')\n",
        "\n",
        "# Entrenar modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1,  # 10% de train para validacion\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f'\\n✅ Entrenamiento completado!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_wA6ktwok73",
        "outputId": "da626174-f5b0-4786-a9b1-6672972d9c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " ENTRENAMIENTO\n",
            "======================================================================\n",
            "\n",
            " Iniciando entrenamiento...\n",
            " Epocas max: 100\n",
            " Batch size: 64\n",
            " Early stopping patience: 15\n",
            "Epoch 1/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0413 - mae: 0.1113\n",
            "Epoch 1: val_loss improved from inf to 0.00521, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0413 - mae: 0.1113 - val_loss: 0.0052 - val_mae: 0.0229 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0419\n",
            "Epoch 2: val_loss improved from 0.00521 to 0.00381, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0419 - val_loss: 0.0038 - val_mae: 0.0344 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - mae: 0.0329\n",
            "Epoch 3: val_loss improved from 0.00381 to 0.00191, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0043 - mae: 0.0329 - val_loss: 0.0019 - val_mae: 0.0157 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0272\n",
            "Epoch 4: val_loss improved from 0.00191 to 0.00165, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0272 - val_loss: 0.0016 - val_mae: 0.0184 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0264\n",
            "Epoch 5: val_loss did not improve from 0.00165\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0264 - val_loss: 0.0025 - val_mae: 0.0371 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0251\n",
            "Epoch 6: val_loss improved from 0.00165 to 0.00136, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0251 - val_loss: 0.0014 - val_mae: 0.0224 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0236\n",
            "Epoch 7: val_loss improved from 0.00136 to 0.00072, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0236 - val_loss: 7.1883e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0226\n",
            "Epoch 8: val_loss did not improve from 0.00072\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0024 - val_mae: 0.0423 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0234\n",
            "Epoch 9: val_loss improved from 0.00072 to 0.00055, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0234 - val_loss: 5.5041e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0213\n",
            "Epoch 10: val_loss did not improve from 0.00055\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 8.7566e-04 - val_mae: 0.0213 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0211\n",
            "Epoch 11: val_loss improved from 0.00055 to 0.00041, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 4.0860e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.8241e-04 - mae: 0.0198\n",
            "Epoch 12: val_loss did not improve from 0.00041\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 9.8249e-04 - mae: 0.0198 - val_loss: 6.2875e-04 - val_mae: 0.0174 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0209\n",
            "Epoch 13: val_loss did not improve from 0.00041\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.0013 - val_mae: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0205\n",
            "Epoch 14: val_loss did not improve from 0.00041\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0293 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.3957e-04 - mae: 0.0195\n",
            "Epoch 15: val_loss improved from 0.00041 to 0.00021, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 9.3945e-04 - mae: 0.0195 - val_loss: 2.0543e-04 - val_mae: 0.0060 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.9392e-04 - mae: 0.0183\n",
            "Epoch 16: val_loss did not improve from 0.00021\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 7.9400e-04 - mae: 0.0183 - val_loss: 3.1046e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.9064e-04 - mae: 0.0184\n",
            "Epoch 17: val_loss did not improve from 0.00021\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 7.9067e-04 - mae: 0.0184 - val_loss: 6.0467e-04 - val_mae: 0.0209 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.9139e-04 - mae: 0.0187\n",
            "Epoch 18: val_loss did not improve from 0.00021\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 7.9135e-04 - mae: 0.0187 - val_loss: 0.0070 - val_mae: 0.0736 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.5366e-04 - mae: 0.0197\n",
            "Epoch 19: val_loss did not improve from 0.00021\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 8.5344e-04 - mae: 0.0197 - val_loss: 4.3226e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.1365e-04 - mae: 0.0190\n",
            "Epoch 20: val_loss improved from 0.00021 to 0.00020, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 8.1354e-04 - mae: 0.0190 - val_loss: 2.0392e-04 - val_mae: 0.0072 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.0163e-04 - mae: 0.0176\n",
            "Epoch 21: val_loss did not improve from 0.00020\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 7.0169e-04 - mae: 0.0176 - val_loss: 9.2754e-04 - val_mae: 0.0271 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.4264e-04 - mae: 0.0181\n",
            "Epoch 22: val_loss improved from 0.00020 to 0.00020, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 7.4253e-04 - mae: 0.0181 - val_loss: 2.0175e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7611e-04 - mae: 0.0171\n",
            "Epoch 23: val_loss did not improve from 0.00020\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 6.7615e-04 - mae: 0.0171 - val_loss: 5.4330e-04 - val_mae: 0.0194 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5428e-04 - mae: 0.0169\n",
            "Epoch 24: val_loss did not improve from 0.00020\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 6.5432e-04 - mae: 0.0169 - val_loss: 2.5355e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.3131e-04 - mae: 0.0167\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.00020\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 6.3137e-04 - mae: 0.0167 - val_loss: 2.6884e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.6808e-04 - mae: 0.0156\n",
            "Epoch 26: val_loss improved from 0.00020 to 0.00014, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.6803e-04 - mae: 0.0156 - val_loss: 1.4292e-04 - val_mae: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.4971e-04 - mae: 0.0154\n",
            "Epoch 27: val_loss improved from 0.00014 to 0.00013, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.4975e-04 - mae: 0.0154 - val_loss: 1.2721e-04 - val_mae: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.6023e-04 - mae: 0.0156\n",
            "Epoch 28: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.6019e-04 - mae: 0.0156 - val_loss: 4.7666e-04 - val_mae: 0.0178 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.4189e-04 - mae: 0.0154\n",
            "Epoch 29: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 5.4188e-04 - mae: 0.0154 - val_loss: 3.5180e-04 - val_mae: 0.0155 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.5862e-04 - mae: 0.0157\n",
            "Epoch 30: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 5.5859e-04 - mae: 0.0157 - val_loss: 3.2661e-04 - val_mae: 0.0145 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.4964e-04 - mae: 0.0155\n",
            "Epoch 31: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.4959e-04 - mae: 0.0155 - val_loss: 4.3348e-04 - val_mae: 0.0170 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.5083e-04 - mae: 0.0157\n",
            "Epoch 32: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.5079e-04 - mae: 0.0157 - val_loss: 1.7223e-04 - val_mae: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4346e-04 - mae: 0.0155\n",
            "Epoch 33: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.4347e-04 - mae: 0.0155 - val_loss: 2.8518e-04 - val_mae: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.3571e-04 - mae: 0.0153\n",
            "Epoch 34: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.3574e-04 - mae: 0.0153 - val_loss: 1.5562e-04 - val_mae: 0.0083 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.3185e-04 - mae: 0.0153\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.3186e-04 - mae: 0.0153 - val_loss: 9.6051e-04 - val_mae: 0.0289 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.9338e-04 - mae: 0.0147\n",
            "Epoch 36: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 4.9336e-04 - mae: 0.0147 - val_loss: 4.7693e-04 - val_mae: 0.0181 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1867e-04 - mae: 0.0148\n",
            "Epoch 37: val_loss did not improve from 0.00013\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 5.1848e-04 - mae: 0.0148 - val_loss: 4.2892e-04 - val_mae: 0.0172 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1771e-04 - mae: 0.0149\n",
            "Epoch 38: val_loss improved from 0.00013 to 0.00010, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 5.1768e-04 - mae: 0.0149 - val_loss: 9.9901e-05 - val_mae: 0.0053 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.8099e-04 - mae: 0.0146\n",
            "Epoch 39: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 4.8096e-04 - mae: 0.0146 - val_loss: 1.9734e-04 - val_mae: 0.0109 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.7083e-04 - mae: 0.0143\n",
            "Epoch 40: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 4.7081e-04 - mae: 0.0143 - val_loss: 2.0502e-04 - val_mae: 0.0109 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.9712e-04 - mae: 0.0146\n",
            "Epoch 41: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.9710e-04 - mae: 0.0146 - val_loss: 1.3548e-04 - val_mae: 0.0076 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8132e-04 - mae: 0.0146\n",
            "Epoch 42: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.8130e-04 - mae: 0.0146 - val_loss: 1.1938e-04 - val_mae: 0.0067 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.7441e-04 - mae: 0.0143\n",
            "Epoch 43: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 4.7436e-04 - mae: 0.0143 - val_loss: 1.6262e-04 - val_mae: 0.0089 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7998e-04 - mae: 0.0145\n",
            "Epoch 44: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.7994e-04 - mae: 0.0145 - val_loss: 2.4829e-04 - val_mae: 0.0126 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.8148e-04 - mae: 0.0145\n",
            "Epoch 45: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.8145e-04 - mae: 0.0145 - val_loss: 5.3027e-04 - val_mae: 0.0198 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7203e-04 - mae: 0.0144\n",
            "Epoch 46: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 4.7202e-04 - mae: 0.0144 - val_loss: 2.7590e-04 - val_mae: 0.0137 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6954e-04 - mae: 0.0145\n",
            "Epoch 47: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.6952e-04 - mae: 0.0145 - val_loss: 2.6983e-04 - val_mae: 0.0134 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5838e-04 - mae: 0.0142\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.00010\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.5841e-04 - mae: 0.0142 - val_loss: 1.4856e-04 - val_mae: 0.0086 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4210e-04 - mae: 0.0139\n",
            "Epoch 49: val_loss improved from 0.00010 to 0.00009, saving model to /content/drive/MyDrive/AchillesTraining/output/v3.1/best_model.keras\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.4209e-04 - mae: 0.0139 - val_loss: 8.7130e-05 - val_mae: 0.0051 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.5263e-04 - mae: 0.0141\n",
            "Epoch 50: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 4.5261e-04 - mae: 0.0141 - val_loss: 1.5935e-04 - val_mae: 0.0096 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3158e-04 - mae: 0.0138\n",
            "Epoch 51: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 4.3158e-04 - mae: 0.0138 - val_loss: 1.2987e-04 - val_mae: 0.0075 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5179e-04 - mae: 0.0140\n",
            "Epoch 52: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.5173e-04 - mae: 0.0140 - val_loss: 1.1352e-04 - val_mae: 0.0070 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4867e-04 - mae: 0.0140\n",
            "Epoch 53: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.4867e-04 - mae: 0.0140 - val_loss: 1.1095e-04 - val_mae: 0.0067 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3080e-04 - mae: 0.0137\n",
            "Epoch 54: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 4.3081e-04 - mae: 0.0137 - val_loss: 1.7864e-04 - val_mae: 0.0103 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3712e-04 - mae: 0.0139\n",
            "Epoch 55: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.3708e-04 - mae: 0.0139 - val_loss: 1.3489e-04 - val_mae: 0.0077 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2912e-04 - mae: 0.0137\n",
            "Epoch 56: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.2919e-04 - mae: 0.0137 - val_loss: 1.0740e-04 - val_mae: 0.0068 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3739e-04 - mae: 0.0138\n",
            "Epoch 57: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 4.3743e-04 - mae: 0.0138 - val_loss: 1.4367e-04 - val_mae: 0.0087 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3771e-04 - mae: 0.0140\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 4.3772e-04 - mae: 0.0140 - val_loss: 1.5060e-04 - val_mae: 0.0091 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m559/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1808e-04 - mae: 0.0136\n",
            "Epoch 59: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.1808e-04 - mae: 0.0136 - val_loss: 9.6359e-05 - val_mae: 0.0062 - learning_rate: 6.2500e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1907e-04 - mae: 0.0134\n",
            "Epoch 60: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.1908e-04 - mae: 0.0134 - val_loss: 8.9208e-05 - val_mae: 0.0057 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2513e-04 - mae: 0.0136\n",
            "Epoch 61: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 4.2514e-04 - mae: 0.0136 - val_loss: 9.5999e-05 - val_mae: 0.0061 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m561/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.2129e-04 - mae: 0.0136\n",
            "Epoch 62: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 4.2129e-04 - mae: 0.0136 - val_loss: 1.6932e-04 - val_mae: 0.0103 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2282e-04 - mae: 0.0136\n",
            "Epoch 63: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.2281e-04 - mae: 0.0136 - val_loss: 1.0762e-04 - val_mae: 0.0070 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m560/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.2407e-04 - mae: 0.0136\n",
            "Epoch 64: val_loss did not improve from 0.00009\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 4.2409e-04 - mae: 0.0136 - val_loss: 9.0530e-05 - val_mae: 0.0058 - learning_rate: 6.2500e-05\n",
            "Epoch 64: early stopping\n",
            "Restoring model weights from the end of the best epoch: 49.\n",
            "\n",
            "✅ Entrenamiento completado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 10: Evaluacion y Metricas\n",
        "# ============================================================\n",
        "print('=' * 70)\n",
        "print(' EVALUACION EN TEST SET')\n",
        "print('=' * 70)\n",
        "\n",
        "# Predecir en test set\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Desnormalizar predicciones y valores reales\n",
        "# Crear array con ceros para las otras features\n",
        "y_pred_padded = np.zeros((len(y_pred_scaled), len(FEATURE_COLUMNS)))\n",
        "y_pred_padded[:, 0] = y_pred_scaled.flatten()\n",
        "y_pred = scaler.inverse_transform(y_pred_padded)[:, 0]\n",
        "\n",
        "y_test_padded = np.zeros((len(y_test), len(FEATURE_COLUMNS)))\n",
        "y_test_padded[:, 0] = y_test\n",
        "y_test_original = scaler.inverse_transform(y_test_padded)[:, 0]\n",
        "\n",
        "# Calcular metricas\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_test_original, y_pred) * 100\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "\n",
        "print(f'\\n METRICAS FINALES:')\n",
        "print(f'   MAE (Mean Absolute Error): ${mae:.2f}')\n",
        "print(f'   MAPE (Mean Absolute % Error): {mape:.2f}%')\n",
        "print(f'   R2 Score: {r2:.4f}')\n",
        "\n",
        "# Comparar con objetivos de la enciclopedia\n",
        "print(f'\\n OBJETIVO ENCICLOPEDIA: MAE < $2.00')\n",
        "if mae < 2.0:\n",
        "    print(f'   ✅ OBJETIVO CUMPLIDO! MAE = ${mae:.2f}')\n",
        "else:\n",
        "    print(f'   ⚠️ Por mejorar. MAE = ${mae:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB8wwt-Yorlm",
        "outputId": "db33c889-6a2d-4ae2-cd53-aa6fadbf8043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " EVALUACION EN TEST SET\n",
            "======================================================================\n",
            "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\n",
            " METRICAS FINALES:\n",
            "   MAE (Mean Absolute Error): $2.58\n",
            "   MAPE (Mean Absolute % Error): 0.06%\n",
            "   R2 Score: 0.9937\n",
            "\n",
            " OBJETIVO ENCICLOPEDIA: MAE < $2.00\n",
            "   ⚠️ Por mejorar. MAE = $2.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 11: Exportar Modelo Achilles para Vertex AI + Full Assets\n",
        "# ===============================================================\n",
        "print('=' * 70)\n",
        "print(' EXPORTANDO MODELO ACHILLES Y ASSETS')\n",
        "print('=' * 70)\n",
        "\n",
        "# EXPORTAR modelo en formato TensorFlow SavedModel (Vertex AI Ready)\n",
        "savedmodel_path = f'{OUTPUTDIR}/achilles_model_export'\n",
        "model.export(savedmodel_path)  # Keras 3 exporta correcto a SavedModel como directorio\n",
        "print(f'\\n✅ SavedModel exportado a directorio: {savedmodel_path}')\n",
        "\n",
        "# EXPORTAR scaler en formato pickle (para preprocessing en producción)\n",
        "scaler_path = f'{OUTPUTDIR}/achilles_scaler_{MODEL_VERSION}.pkl'\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(f'✅ Scaler guardado: {scaler_path}')\n",
        "\n",
        "# EXPORTAR metadata del modelo en JSON (info para Vertex AI, Akiles y debugging futuro)\n",
        "metadata = {\n",
        "    'model_version': MODEL_VERSION,\n",
        "    'training_date': datetime.now().isoformat(),\n",
        "    'window_size': WINDOW_SIZE,\n",
        "    'features': FEATURE_COLUMNS,\n",
        "    'metrics': {\n",
        "        'mae': float(mae),\n",
        "        'mape': float(mape),\n",
        "        'r2': float(r2)\n",
        "    },\n",
        "    'hyperparameters': {\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE\n",
        "    }\n",
        "}\n",
        "metadata_path = f'{OUTPUTDIR}/model_metadata_{MODEL_VERSION}.json'\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "print(f'✅ Metadata guardada: {metadata_path}')\n",
        "\n",
        "# RESUMEN FINAL (listado completo de assets para Vertex AI)\n",
        "print(f'\\n' + '=' * 70)\n",
        "print(' ARCHIVOS GENERADOS')\n",
        "print('=' * 70)\n",
        "print(f' 1. {savedmodel_path}/')         # SavedModel DIR\n",
        "print(f' 2. {scaler_path}')              # Scaler PKL\n",
        "print(f' 3. {metadata_path}')            # Metadata JSON\n",
        "print(f'\\n🚀 Modelo listo para desplegar en Vertex AI!')\n",
        "print(f'\\n Siguiente paso: Subir a gs://llm1337-trading-data/models/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvfcge2aWMBL",
        "outputId": "647769be-8c5f-4ea5-bddc-763b37fdf5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " EXPORTANDO MODELO ACHILLES Y ASSETS\n",
            "======================================================================\n",
            "Saved artifact at '/content/drive/MyDrive/AchillesTraining/output/v3.1/achilles_model_export'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 9), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132680547996240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680548001616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680547999696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680547997008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680567278288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542821008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542822928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542824272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542824080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542821200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542819856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542817360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542817936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542826576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542818512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542816208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542817744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132680542819088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\n",
            "✅ SavedModel exportado a directorio: /content/drive/MyDrive/AchillesTraining/output/v3.1/achilles_model_export\n",
            "✅ Scaler guardado: /content/drive/MyDrive/AchillesTraining/output/v3.1/achilles_scaler_v3.1.0.pkl\n",
            "✅ Metadata guardada: /content/drive/MyDrive/AchillesTraining/output/v3.1/model_metadata_v3.1.0.json\n",
            "\n",
            "======================================================================\n",
            " ARCHIVOS GENERADOS\n",
            "======================================================================\n",
            " 1. /content/drive/MyDrive/AchillesTraining/output/v3.1/achilles_model_export/\n",
            " 2. /content/drive/MyDrive/AchillesTraining/output/v3.1/achilles_scaler_v3.1.0.pkl\n",
            " 3. /content/drive/MyDrive/AchillesTraining/output/v3.1/model_metadata_v3.1.0.json\n",
            "\n",
            "🚀 Modelo listo para desplegar en Vertex AI!\n",
            "\n",
            " Siguiente paso: Subir a gs://llm1337-trading-data/models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/AchillesTraining/ACHILLES-LSTM-V3.1-Training.ipynb\" \"/content/\"\n",
        "!jupyter nbconvert --to html \"/content/ACHILLES-LSTM-V3.1-Training.ipynb\"\n",
        "# El HTML aparecerá en /content/ACHILLES-LSTM-V3.1-Training.html\n",
        "# Luego lo puedes mover a Drive si lo quieres:\n",
        "!mv \"/content/ACHILLES-LSTM-V3.1-Training.html\" \"/content/drive/MyDrive/AchillesTraining/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8agTkpdHVX",
        "outputId": "e4aa43b7-13dc-4c30-8b13-8928dcd320ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/AchillesTraining/ACHILLES-LSTM-V3.1-Training.ipynb': No such file or directory\n",
            "[NbConvertApp] WARNING | pattern '/content/ACHILLES-LSTM-V3.1-Training.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n",
            "mv: cannot stat '/content/ACHILLES-LSTM-V3.1-Training.html': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}